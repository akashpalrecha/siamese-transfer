# Siamese-transfer
> Over the years, the AI community has witnessed how subfileds like Computer Vision and NLP suddenly took off in a massive way as soon as somebody figured out how to apply transfer learning in those contexts. (Imagenet Pretrained Models for CV, ULMFiT for NLP). This project aims to make transfer learning work for Siamese Networks and possibly motivate more such attempts in other few-shot learning approaches.


Key points:
1. I aim to make few-shot learning as easy to implement and train as standard image classification models (Resnets, Inception, etc.). The reason for this is that most research these days is highly specialized and specific to the task at hand, and difficult implement, teach and maintain in practice. This causes majority of the papers ever published to just get lost on arxiv within days after their publication. Forgotten research is essentially research that never happened. And this is exactly what I want to avoid.
2. This will be done by trying to constrain myself into using only the most common off the shelf components to make this work (Pretrained Resnets, common datasets like Imagenet, CIFAR100, etc).
3. Specifically, I aim to have all of this work without making any change in a normal Resnet as a first goal.
4. Other things will follow once I'm done with the above

You can see the model training and results by visiting the links visible in the sidebar.
<br>
I am not working full time on this project. I will keep updating the training notebooks as I make progress here.

## Install

`TODO`

## How to use

`TODO`
